# 35：管道

最后一章，实现管道，可以支持父子进程通信。



进程虽然是独立运行的个体，但他们之间有时候需要协作才能完成一项任务，比如两个进程需要同步数据，进程A把数据准备好后，想把数据发往进程B，进程B必须被提前通知有数据即将到来，或者进程A想发送信号给进程B以控制进程B的运行模式，再或者数据被多个进程共享时，数据变更后该被所有进程所看到，等，总之OS必须实现进程间的相互通信IPC。

IPC有多种方式：消息队列，共享内存，socket网络通信等，还有一种就是管道。

管道是进程间通信的方式之一,在Linux中一切皆文件，因此管道也被视为文件，只是该文件并不存在文件系统上，而是存在于内存中。管道通常被多个进程共享，而且存在于内存之中，**因此内存共享的原理是所有进程在空间中都能访问它。**说白了，管道其实就是内核空间中的内存缓冲区。当然，进程间也可以通过文件系统，也就是多个进程可以共同读写磁盘上的同一个文件来实现share，但是太慢。



管道不知道传送的数据有多大，故实现为“弹力”缓冲区，即环形缓冲区。

环形缓冲区，当满了时生产者停止，当空了消费者停止，这样就保证了文件不丢失。管道就是典型的消费者和生产者问题。



管道有两端，一端用于管道中读入数据，另一端写入数据，这两端使用文件描述符的方式来读取，故进程创建管道实际上就是内核为其返回了用于读取管道缓冲区的文件描述符，一个用于读，一个用于写。



管道对于父子进程来说一般不会同时写同时读，所以父子进程关闭那些他们不用的管道，只留一个管道，且一个读一个写。

管道分为两种，匿名管道和命名管道，匿名管道没有名字，由于它没有名字，匿名管道创建之后只能通过内核为其返回的文件描述符访问，此管道只对创建它的进程和子进程可见，对其他进程不可见，因此除父子进程之外的其他进程便不知道此管道的存在，故匿名管道只能局限于父子进程间的通信。

![image-20220822114249758](C:\Users\Administrator\Desktop\备份\TYPIC\image-20220822114249758.png)

有名管道是专门为解决匿名管道的局限性而生的，在Linux中可以通过命令mkfifo来创建管道，成功之后便会在文件系统上存在个管道文件，这使得该管道对任何进程都“可见”，因此多个进程即使没有父子进程也都可以通过该管道访问。

![image-20220822114318531](C:\Users\Administrator\Desktop\备份\TYPIC\image-20220822114318531.png)

文件结构的成员名称已经是固定的了，再改变的话成本太高，现在也不想增加额外的成员，因此只能 把成员的作用改变。在这之前，文件结构对应一个普通文件或目录的 inode，现在多了管道这种新的文件 类型，而管道不需要 inode，那如何在文件结构中识别管道，而不是误把它当成一般的 inode 来处理呢？ 看来咱们得想办法在文件结构中为管道加个标志。这里的方法是把 fd_flags 成员动动手脚，如果此文件结 构对应的是管道，那么 fd_flags 的值将是 0xFFFF，不再是 O_RDONLY、O_WRONLY 等值。另外，管道 得有个存储数据的内存缓冲区，因此咱们把文件结构中的 fd_inode 指向管道的内存缓冲区，至于 fd_pos 嘛，咱们就把它用于此管道的打开数。经过复用以上三个成员，咱们的文件结构依然能够满足管道的需求。





![image-20220822115142466](C:\Users\Administrator\Desktop\备份\TYPIC\image-20220822115142466.png)

管道的实现

```c

/* 判断文件描述符local_fd是否是管道 */
bool is_pipe(uint32_t local_fd) {
   uint32_t global_fd = fd_local2global(local_fd); 
   return file_table[global_fd].fd_flag == PIPE_FLAG;
}

/* 创建管道,成功返回0,失败返回-1 */
int32_t sys_pipe(int32_t pipefd[2]) {
   int32_t global_fd = get_free_slot_in_global();

   /* 申请一页内核内存做环形缓冲区 */
   file_table[global_fd].fd_inode = get_kernel_pages(1); 

   /* 初始化环形缓冲区 */
   ioqueue_init((struct ioqueue*)file_table[global_fd].fd_inode);
   if (file_table[global_fd].fd_inode == NULL) {
      return -1;
   }
  
   /* 将fd_flag复用为管道标志 */
   file_table[global_fd].fd_flag = PIPE_FLAG;

   /* 将fd_pos复用为管道打开数 */
   file_table[global_fd].fd_pos = 2;
   pipefd[0] = pcb_fd_install(global_fd);
   pipefd[1] = pcb_fd_install(global_fd);
   return 0;
}

/* 从管道中读数据 */
uint32_t pipe_read(int32_t fd, void* buf, uint32_t count) {
   char* buffer = buf;
   uint32_t bytes_read = 0;
   uint32_t global_fd = fd_local2global(fd);

   /* 获取管道的环形缓冲区 */
   struct ioqueue* ioq = (struct ioqueue*)file_table[global_fd].fd_inode;

   /* 选择较小的数据读取量,避免阻塞 */
   uint32_t ioq_len = ioq_length(ioq);
   uint32_t size = ioq_len > count ? count : ioq_len;
   while (bytes_read < size) {
      *buffer = ioq_getchar(ioq);
      bytes_read++;
      buffer++;
   }
   return bytes_read;
}

/* 往管道中写数据 */
uint32_t pipe_write(int32_t fd, const void* buf, uint32_t count) {
   uint32_t bytes_write = 0;
   uint32_t global_fd = fd_local2global(fd);
   struct ioqueue* ioq = (struct ioqueue*)file_table[global_fd].fd_inode;

   /* 选择较小的数据写入量,避免阻塞 */
   uint32_t ioq_left = bufsize - ioq_length(ioq);
   uint32_t size = ioq_left > count ? count : ioq_left;

   const char* buffer = buf;
   while (bytes_write < size) {
      ioq_putchar(ioq, *buffer);
      bytes_write++;
      buffer++;
   }
   return bytes_write;
}

/* 将文件描述符old_local_fd重定向为new_local_fd */
void sys_fd_redirect(uint32_t old_local_fd, uint32_t new_local_fd) {
   struct task_struct* cur = running_thread();
   /* 针对恢复标准描述符 */
   if (new_local_fd < 3) {
      cur->fd_table[old_local_fd] = new_local_fd;
   } else {
      uint32_t new_global_fd = cur->fd_table[new_local_fd];
      cur->fd_table[old_local_fd] = new_global_fd;
   }
}
```

