## 23：完善内存管理

内存对CPU来说都是全部可使用的，都是一视同仁的，但是用我们的视角来看，是有空闲与不空闲的区分，这么做是为了我们方便管理内存，我们管理内存的手段只是通过内存位图。

简单来说，我们通过内存位图里面的空闲bit的idx * PG_SIZE 即可得到“空闲”内存块的首地址。

之前的内存分配，内存释放都是以页框单位进行操作的，而我们的目的是要实现任意大小的内存分配释放，于是有了arena结构。

内存分配虚拟内存和物理内存，这是概念上的分，不是物理上的区分。

按物理上的区分且以我们的视角认为其管理形式分为**内核物理内存池**和**用户物理内存池**

相应的概念上分为 内核虚拟内存池和用户虚拟内存池。

**内核的内存的基址都是固定的，而各个用户程序的内存基址不固定。**

###### 底层初始化

```c
/* 内存块结构，其值是用来存在内存块描述符的free_list之中 */
struct mem_block {
   struct list_elem free_elem;
};


/* 内存块描述符，free_list是可用来分配的内存块 */
struct mem_block_desc {
   uint32_t block_size;		 // 内存块大小
   uint32_t blocks_per_arena;	 // 本arena中可容纳此mem_block的数量.
   struct list free_list;	 // 目前可用的mem_block链表
};

#define DESC_CNT 7  
共有7种内存块，从 16 字节起，分别是 16、32、64、128、256、512、1024 字节，共有 7 种规格的
内存块。对于小内存的 arena 来说，其大小是一页框 4096 字节，其中的内存块是大小一致的。除了元信息占
用的内存外，arena 中不能同时容纳两个 2048 的内存块，2048 下一级内存规格就是 1024，故最大的内存块就
是 1024 字节。当申请的内存大小超过 1024 时就直接返回一个页框，不再从 arena 中划分，因为意义不大。
    
    
一个内存块描述符其free_list里面的内存块可能包括多个arena，即是一种一对多的形式
    
    
    
struct arena {
   struct mem_block_desc* desc;	 // 此arena关联的mem_block_desc，指向内存块描述符，间接知道本arena的块类型
   uint32_t cnt;/* large为ture时,cnt表示的是页框数。 * 否则cnt表示空闲mem_block数量 */
   bool large;		   
};


```



![image-20220813171705778](D:/TYPIC/image-20220813171705778.png)

一个arena里面包括的内存碎片类型只有一种。

对于内存块大小的不同处理

![image-20220813171815785](D:/TYPIC/image-20220813171815785.png)









###### 内存的分配



```c
/* 为malloc做准备 */
void block_desc_init(struct mem_block_desc* desc_array) {				   
   uint16_t desc_idx, block_size = 16;

   /* 初始化每个mem_block_desc描述符 */
   for (desc_idx = 0; desc_idx < DESC_CNT; desc_idx++) {
      desc_array[desc_idx].block_size = block_size;

      /* 初始化arena中的内存块数量 */
      desc_array[desc_idx].blocks_per_arena = (PG_SIZE - sizeof(struct arena)) / block_size;	  

      list_init(&desc_array[desc_idx].free_list);

      block_size *= 2;         // 更新为下一个规格内存块
   }
}
初始化内存描述符的七种大小及各种信息，链表队列
```

七种不同的内存块描述符是管理各种arena里面的内存块，用链表形式管理

用户程序有用户的内存块描述符，因为其开辟的是用户内存池中的内存，内核有内核的内存块描述符，因为其开辟的是内核内存池中的内存。

PCB改进

```c
/* 进程或线程的 pcb，程序控制块 */ 
  struct task_struct { 
  uint32_t* self_kstack; // 各内核线程都用自己的内核栈
  pid_t pid; 
…略
  uint32_t* pgdir; // 进程自己页表的虚拟地址
  
  struct virtual_addr userprog_vaddr; // 用户进程的虚拟地址
  struct mem_block_desc u_block_desc[DESC_CNT]; 
// 用户进程内存块描述符
…略
 }; 



 /* 创建用户进程 */ 
  void process_execute(void* filename, char* name) { 
…略
 thread->pgdir = create_page_dir(); 
 block_desc_init(thread->u_block_desc); 
…略
 } 

```













```c
/* 返回arena中第idx个内存块的地址 */
static struct mem_block* arena2block(struct arena* a, uint32_t idx) {
  return (struct mem_block*)((uint32_t)a + sizeof(struct arena) + idx * a->desc->block_size);
}

/* 返回内存块b所在的arena地址 */
static struct arena* block2arena(struct mem_block* b) {
   return (struct arena*)((uint32_t)b & 0xfffff000);
}




/* 在堆中申请size字节内存 */
void* sys_malloc(uint32_t size) {
   enum pool_flags PF;
   struct pool* mem_pool;
   uint32_t pool_size;
   struct mem_block_desc* descs;
   struct task_struct* cur_thread = running_thread();

/* 判断用哪个内存池*/
   if (cur_thread->pgdir == NULL) {     // 若为内核线程
      PF = PF_KERNEL; 
      pool_size = kernel_pool.pool_size;
      mem_pool = &kernel_pool;
      descs = k_block_descs;
   } else {				      // 用户进程pcb中的pgdir会在为其分配页表时创建
      PF = PF_USER;
      pool_size = user_pool.pool_size;
      mem_pool = &user_pool;
      descs = cur_thread->u_block_desc;
   }

   /* 若申请的内存不在内存池容量范围内则直接返回NULL */
   if (!(size > 0 && size < pool_size)) {
      return NULL;
   }
   struct arena* a;
   struct mem_block* b;	
   lock_acquire(&mem_pool->lock);

/* 超过最大内存块1024, 就分配页框 */
   if (size > 1024) {
      uint32_t page_cnt = DIV_ROUND_UP(size + sizeof(struct arena), PG_SIZE);    // 向上取整需要的页框数

      a = malloc_page(PF, page_cnt);

      if (a != NULL) {
	 memset(a, 0, page_cnt * PG_SIZE);	 // 将分配的内存清0  

      /* 对于分配的大块页框,将desc置为NULL, cnt置为页框数,large置为true */
	 a->desc = NULL;
	 a->cnt = page_cnt;
	 a->large = true;
	 lock_release(&mem_pool->lock);
	 return (void*)(a + 1);		 // 跨过arena大小，把剩下的内存返回
      } else { 
	 lock_release(&mem_pool->lock);
	 return NULL; 
      }
   } else {    // 若申请的内存小于等于1024,可在各种规格的mem_block_desc中去适配
      uint8_t desc_idx;
      
      /* 从内存块描述符中匹配合适的内存块规格 */
      for (desc_idx = 0; desc_idx < DESC_CNT; desc_idx++) {
	 if (size <= descs[desc_idx].block_size) {  // 从小往大后,找到后退出
	    break;
	 }
      }

   /* 若mem_block_desc的free_list中已经没有可用的mem_block,
    * 就创建新的arena提供mem_block */
      if (list_empty(&descs[desc_idx].free_list)) {
	 a = malloc_page(PF, 1);       // 分配1页框做为arena
	 if (a == NULL) {
	    lock_release(&mem_pool->lock);
	    return NULL;
	 }
	 memset(a, 0, PG_SIZE);

    /* 对于分配的小块内存,将desc置为相应内存块描述符, 
     * cnt置为此arena可用的内存块数,large置为false */
	 a->desc = &descs[desc_idx];
	 a->large = false;
	 a->cnt = descs[desc_idx].blocks_per_arena;
	 uint32_t block_idx;

	 enum intr_status old_status = intr_disable();

	 /* 开始将arena拆分成内存块,并添加到内存块描述符的free_list中 */
	 for (block_idx = 0; block_idx < descs[desc_idx].blocks_per_arena; block_idx++) {
	    b = arena2block(a, block_idx);
	    ASSERT(!elem_find(&a->desc->free_list, &b->free_elem));
	    list_append(&a->desc->free_list, &b->free_elem);	
	 }
	 intr_set_status(old_status);
      }    

   /* 开始分配内存块 */
      b = elem2entry(struct mem_block, free_elem, list_pop(&(descs[desc_idx].free_list)));
      memset(b, 0, descs[desc_idx].block_size);

      a = block2arena(b);  // 获取内存块b所在的arena
      a->cnt--;		   // 将此arena中的空闲内存块数减1
      lock_release(&mem_pool->lock);
      return (void*)b;
   }
}
```

这便是内存的分配。











###### 内存的释放

我们分配内存一般步骤如下：

1.在虚拟内存池中分配虚拟地址，相关函数是vaddr_get,此函数操作的是内核虚拟内存池位图或用户虚拟内存池位图

2.在物理内存池中分配物理地址。

3.在页表中完成虚拟地址到物理地址的映射。相关函数是page_table_add

以上三个函数封装在malloc_page中



释放内存与分配内存是相反的过程，咱们对照着设计一套释放内存的方法

1.在物理内存池中释放物理页地址，相关函数是pfree

2.在页表中去掉虚拟地址的映射，原理是将虚拟地址对应的PTE的P位置0，相关函数是page_table_pte_remove. 无论PTE指向的是不是一个物理页，CPU根据PTE中的P位判定是不是有效的。

3.在虚拟地址池中释放虚拟地址，相关的函数是vaddr_remove。

以上三个函数封装在mfree_page中。



```c
/* 将物理地址pg_phy_addr回收到物理内存池 */
void pfree(uint32_t pg_phy_addr) {
   struct pool* mem_pool;
   uint32_t bit_idx = 0;
   if (pg_phy_addr >= user_pool.phy_addr_start) {     // 用户物理内存池
      mem_pool = &user_pool;
      bit_idx = (pg_phy_addr - user_pool.phy_addr_start) / PG_SIZE;
   } else {	  // 内核物理内存池
      mem_pool = &kernel_pool;
      bit_idx = (pg_phy_addr - kernel_pool.phy_addr_start) / PG_SIZE;
   } 
   bitmap_set(&mem_pool->pool_bitmap, bit_idx, 0);	 // 将位图中该位清0
}
参数接受物理页框的地址，判断pg_phy_addr是哪个物理内存池的，随后算出bit_idx，最后在bitmap中置位
    
    
/* 去掉页表中虚拟地址vaddr的映射,只去掉vaddr对应的pte */
static void page_table_pte_remove(uint32_t vaddr) {
   uint32_t* pte = pte_ptr(vaddr);
   *pte &= ~PG_P_1;	// 将页表项pte的P位置0
   asm volatile ("invlpg %0"::"m" (vaddr):"memory");    //更新tlb
}    
接受虚拟地址vaddr，将pte的P位置于0，同时因为映射改变，需要在快表TLB中更新项目；
    
    
    
/*
刷新 tlb。pte 已
经被修改，因此咱们要把此 pte 更新到 tlb 中，还记得 tlb 吗？它是页表的高速缓存，俗称快表，tlb 是处理
器提供的、用于加速虚拟地址到物理地址的转换过程。当页表发生变化时，tlb 中缓存的数据也应该及时
更新，否则程序会运行出错。更新 TLB 有两种方式，一是用 invlpg 指令更新单条虚拟地址条目，另外一
个是重新加载 cr3 寄存器，这将直接清空 TLB，相当于更新整个页表。咱们这里只更新了虚拟地址 vaddr
对应的 pte，因此不至于大动干戈针对整个 TLB，咱们采用温柔一点的 invlpg 指令去单独更新 vaddr 对应
的缓存。invlpg 的指令格式为“invlpg m”，其中 m 是操作数，表示虚拟地址内存，注意，m 并不是立即
数形式的虚拟地址，它必须是实实在在的内存地址的形式。比如更新虚拟地址 0x12345678 的缓存，指令
是 invalpg [0x12345678]，而不是 invalpg 0x12345678。invalpg 是汇编指令，因此用下面的一行内联汇编代
码“asm volatile ("invlpg %0"::"m" (vaddr):"memory")”来更新虚拟地址 vaddr 在 tlb 缓存中的条目，也就是
把页表中 vaddr 所在的 pte 重新写入 tlb。注意，invlpg 的操作数 m 是内存地址，因此位于内联汇编代码输
入部中的 vaddr，其约束是内存约束 m。
*/

    
/* 在虚拟地址池中释放以_vaddr起始的连续pg_cnt个虚拟页地址 */
static void vaddr_remove(enum pool_flags pf, void* _vaddr, uint32_t pg_cnt) {
   uint32_t bit_idx_start = 0, vaddr = (uint32_t)_vaddr, cnt = 0;

   if (pf == PF_KERNEL) {  // 内核虚拟内存池
      bit_idx_start = (vaddr - kernel_vaddr.vaddr_start) / PG_SIZE;
      while(cnt < pg_cnt) {
	 bitmap_set(&kernel_vaddr.vaddr_bitmap, bit_idx_start + cnt++, 0);
      }
   } else {  // 用户虚拟内存池
      struct task_struct* cur_thread = running_thread();
      bit_idx_start = (vaddr - cur_thread->userprog_vaddr.vaddr_start) / PG_SIZE;
      while(cnt < pg_cnt) {
	 bitmap_set(&cur_thread->userprog_vaddr.vaddr_bitmap, bit_idx_start + cnt++, 0);
      }
   }
}    
内核的内存池是固定的，而用户虚拟内存池是在各自的PCB之中，各自的PCB有各自的虚拟地址页表，加载的CR3中。
    
    
```

这是mfree_page的三大核心

接下来是mfree_page,释放vaddr_remove里面对应的虚拟地址的物理地址，参数同vaddr_remove中三个参数，也是以上三个核心的集成函数：先调用pfree清空物理地址位图中的相应位，再调用page_table_pte_remove删除页表中此地址的PTE，最后调用vaddr_remove释放虚拟地址vaddr为起始的cnt个物理页框。

```c
/* 释放以虚拟地址vaddr为起始的cnt个物理页框 */
void mfree_page(enum pool_flags pf, void* _vaddr, uint32_t pg_cnt) {
   uint32_t pg_phy_addr;
   uint32_t vaddr = (int32_t)_vaddr, page_cnt = 0;
   ASSERT(pg_cnt >=1 && vaddr % PG_SIZE == 0); 
   pg_phy_addr = addr_v2p(vaddr);  // 获取虚拟地址vaddr对应的物理地址

/* 确保待释放的物理内存在低端1M+1k大小的页目录+1k大小的页表地址范围外 */
   ASSERT((pg_phy_addr % PG_SIZE) == 0 && pg_phy_addr >= 0x102000);
   
/* 判断pg_phy_addr属于用户物理内存池还是内核物理内存池 */
   if (pg_phy_addr >= user_pool.phy_addr_start) {   // 位于user_pool内存池
      vaddr -= PG_SIZE;
      while (page_cnt < pg_cnt) {
	 vaddr += PG_SIZE;
	 pg_phy_addr = addr_v2p(vaddr);

	 /* 确保物理地址属于用户物理内存池 */
	 ASSERT((pg_phy_addr % PG_SIZE) == 0 && pg_phy_addr >= user_pool.phy_addr_start);

	 /* 先将对应的物理页框归还到内存池 */
	 pfree(pg_phy_addr);

         /* 再从页表中清除此虚拟地址所在的页表项pte */
	 page_table_pte_remove(vaddr);

	 page_cnt++;
      }
   /* 清空虚拟地址的位图中的相应位 */
      vaddr_remove(pf, _vaddr, pg_cnt);

   } else {	     // 位于kernel_pool内存池
      vaddr -= PG_SIZE;	      
      while (page_cnt < pg_cnt) {
	 vaddr += PG_SIZE;
	 pg_phy_addr = addr_v2p(vaddr);
      /* 确保待释放的物理内存只属于内核物理内存池 */
	 ASSERT((pg_phy_addr % PG_SIZE) == 0 && \
	       pg_phy_addr >= kernel_pool.phy_addr_start && \
	       pg_phy_addr < user_pool.phy_addr_start);
	
	 /* 先将对应的物理页框归还到内存池 */
	 pfree(pg_phy_addr);

         /* 再从页表中清除此虚拟地址所在的页表项pte */
	 page_table_pte_remove(vaddr);

	 page_cnt++;
      }
   /* 清空虚拟地址的位图中的相应位 */
      vaddr_remove(pf, _vaddr, pg_cnt);
   }
}



有一点提醒，根据pg_phy_addr的值判定其属于内核的物理内存池还是用户物理内存池。内核物理内存池kernel_pool的地址位于童虎物理内存池user_pool的前面。即kernel_pool的地址在低地址处。

```

距离系统调用free不远了。

我们已经实现了mfree_page，但是只能释放以页框为单位的内存块，这并不能满足我们的需求，我们的需求是要支持释放任意字节的内存，而这就是sys_free的使命，sys_free是内核调用free的内核功能函数，sys_free是基于mfree_page和arena。

sys_free是内存释放的统一接口，无论是页框级别的内存还是小的内存块，都统一用sys_free处理。因此，sys_free针对这两种内存的处理各自有各自的方法，**对于大内存的处理称之为释放，就是把页框在虚拟内存池和物理内存池的位图中将相应位置0。对于小内存的处理称之为回收，是将arena中的内存块重新放回到内存块描述符中的空闲块链表free_list。若arena中所有的内存块都是空闲的，则释放该arena**

```c
/* 回收内存ptr */
void sys_free(void* ptr) {
   ASSERT(ptr != NULL);
   if (ptr != NULL) {
      enum pool_flags PF;
      struct pool* mem_pool;

   /* 判断是线程还是进程 */
      if (running_thread()->pgdir == NULL) {
	 ASSERT((uint32_t)ptr >= K_HEAP_START);
	 PF = PF_KERNEL; 
	 mem_pool = &kernel_pool;
      } else {
	 PF = PF_USER;
	 mem_pool = &user_pool;
      }

      lock_acquire(&mem_pool->lock);   
      struct mem_block* b = ptr;
      struct arena* a = block2arena(b);	     // 把mem_block转换成arena,获取元信息
      ASSERT(a->large == 0 || a->large == 1);
      if (a->desc == NULL && a->large == true) { // 大于1024的内存
	 mfree_page(PF, a, a->cnt); 
      } else {				 // 小于等于1024的内存块
	 /* 先将内存块回收到free_list */
	 list_append(&a->desc->free_list, &b->free_elem);

	 /* 再判断此arena中的内存块是否都是空闲,如果是就释放arena */
	 if (++a->cnt == a->desc->blocks_per_arena) {
	    uint32_t block_idx;
	    for (block_idx = 0; block_idx < a->desc->blocks_per_arena; block_idx++) {
	       struct mem_block*  b = arena2block(a, block_idx);
	       ASSERT(elem_find(&a->desc->free_list, &b->free_elem));
	       list_remove(&b->free_elem);
	    }
	    mfree_page(PF, a, 1); 
	 } 
      }   
      lock_release(&mem_pool->lock); 
   }
}

```



###### 增加系统调用malloc和free

内核态功能已经实现完毕，现在需要写一个用户接口，形成系统调用

```c
#ifndef __LIB_USER_SYSCALL_H
#define __LIB_USER_SYSCALL_H
#include "stdint.h"
enum SYSCALL_NR {
   SYS_GETPID,
   SYS_WRITE,
   SYS_MALLOC,
   SYS_FREE
};
uint32_t getpid(void);
uint32_t write(char* str);
void* malloc(uint32_t size);
void free(void* ptr);
#endif
```



接着在syscall.c完成用户态系统调用实现

```c
void* malloc(uint32_t size) {
   return (void*)_syscall1(SYS_MALLOC, size);
}

/* 释放ptr指向的内存 */
void free(void* ptr) {
   _syscall1(SYS_FREE, ptr);
}
```



至此，系统调用实现成功，我们实现了任意字节的内存分配与内存释放，并包装成了系统调用









最后一点，内核线程共享内存空间，因此线程函数所申请的内存是内核内存，它们申请的内存有地址累加的情况。而用户进程拥有独立的内存空间，其所申请的内存是用户内存，因此在申请的时候，都会从自己的堆空间从头算起，每个用户进程的虚拟地址规划对各自内部是一样的，但是每次不同的用户进程加载，其拥有不同的页表,CR3会加载不同的PCB页表故相同的虚拟地址在不同的PCB代表的物理内存不同。而所有内核程序加载的一定是内核的页表不会变，故虚拟地址唯一。

![image-20220813175416888](D:/TYPIC/image-20220813175416888.png)

在图下面的框框中，用户进程 prog_a 三次 malloc 调用，返回的地址分别是 0x804800c、0x804810c、 0x804820c，它们各相差 0x100，也就是差 256 字节，用户进程 prog_b 与它相同，原因是用户进程独享内 存空间，虚拟地址并不冲突。线程 thread_a 调用 sys_malloc 后返回的地址分别是 0xc013400c、0xc013410c、 0xc013420c，地址之间也是相差 0x100，即 256 字节。下面的线程 thread_b 同样调用 sys_malloc，返回的 地址出现了累加的现象，在 k_thread_a 地址分配的基础上，从 0xc013430c 开始，然后依次是 0xc013440c 和 0xc013450c，原因是内核线程共享内存空间，虚拟地址必须唯一。